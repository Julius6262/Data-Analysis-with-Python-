{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Analysis with Python\n",
    "\n",
    "Contact: Veli MÃ¤kinen veli.makinen@helsinki.fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following assignments introduce applications of hashing with ```dict()``` primitive of Python. While doing so, a rudimentary introduction to biological sequences is given. \n",
    "This framework is then enhanced with probabilities, leading to routines to generate random sequences under some constraints, including a general concept of *Markov-chains*. All these components illustrate the usage of ```dict()```, but at the same time introduce some other computational routines to efficiently deal with probabilities.   \n",
    "The function ```collections.defaultdict``` can be useful.\n",
    "\n",
    "Below are some \"suggested\" imports. Feel free to use and modify these, or not. Generally it's good practice to keep most or all imports in one place. Typically very close to the start of notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2070,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.831112Z",
     "start_time": "2019-07-08T22:04:22.688031Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The automated TMC tests do not test cell outputs. These are intended to be evaluated in the peer reviews. So it is still be a good idea to make the outputs as clear and informative as possible.\n",
    "\n",
    "To keep TMC tests running as well as possible it is recommended to keep global variable assignments in the notebook to a minimum to avoid potential name clashes and confusion. Additionally you should keep all actual code exection in main guards to keep the test running smoothly. If you run [check_sequence.py](https://raw.githubusercontent.com/saskeli/data-analysis-with-python-summer-2019/master/check_outputs.py) in the `part07-e01_sequence_analysis` folder, the script should finish very quickly and optimally produce no output.\n",
    "\n",
    "If you download data from the internet during execution (codon usage table), the parts where downloading is done should not work if you decide to submit to the tmc server. Local tests should work fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNA and RNA\n",
    "\n",
    "A DNA molecule consist, in principle, of a chain of smaller molecules. These smaller molecules have some common basic components (bases) that repeat. For our purposes it is sufficient to know that these bases are nucleotides adenine, cytosine, guanine, and thymine with abbreviations ```A```, ```C```, ```G```, and ```T```. Given a *DNA sequence* e.g. ```ACGATGAGGCTCAT```, one can reverse engineer (with negligible loss of information) the corresponding DNA molecule.\n",
    "\n",
    "Parts of a DNA molecule can *transcribe* into an RNA molecule. In this process, thymine gets replaced by uracil (```U```). \n",
    "\n",
    "\n",
    "1. Write a function ```dna_to_rna``` to convert a given DNA sequence $s$ into an RNA sequence. For the sake of exercise, use ```dict()``` to store the symbol to symbol encoding rules. Create a program to test your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2071,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.841952Z",
     "start_time": "2019-07-08T22:04:22.834721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AACGUGAUUUC\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def dna_to_rna(s):\n",
    "    transcribe = {\"T\": \"U\"}\n",
    "    rna = [transcribe[nucl] if nucl in transcribe else nucl for nucl in s]\n",
    "    return ''.join(rna)\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    print(dna_to_rna(\"AACGTGATTTC\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "\"\"\"There is only one letter that should be substituted, there for we only need to search for that one. So we iterate over the given string, and the comprehensive list, is checking each character in the string to see if it is in the dictionary. If it's not the character remains the same, if it matches the value is return \"U\". The comprehansive list returns a list, where each charater has it own index. There for we need to use the join method for the list to be returned as a string \"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "\"\"\"It worked as excepted, honestly there is not much to discuss yet\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proteins\n",
    "\n",
    "Like DNA and RNA, protein molecule can be interpreted as a chain of smaller molecules, where the bases are now amino acids. RNA molecule may *translate* into a protein molecule, but instead of base by base, three bases of RNA correspond to one base of protein. That is, RNA sequence is read triplet (called codon) at a time. \n",
    "\n",
    "2. Consider the codon to amino acid conversion table in http://htmlpreview.github.io/?https://github.com/csmastersUH/data_analysis_with_python_2020/blob/master/Codon%20usage%20table.html. Write a function ```get_dict``` to read the table into a ```dict()```, such that for each RNA sequence of length 3, say $\\texttt{AGU}$, the hash table stores the conversion rule to the corresponding amino acid. You may store the html page to your local src directory,\n",
    "and parse that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2072,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.867855Z",
     "start_time": "2019-07-08T22:04:22.845885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'UUU': 'F', 'UCU': 'S', 'UAU': 'Y', 'UGU': 'C', 'UUC': 'F', 'UCC': 'S', 'UAC': 'Y', 'UGC': 'C', 'UUA': 'L', 'UCA': 'S', 'UAA': '*', 'UGA': '*', 'UUG': 'L', 'UCG': 'S', 'UAG': '*', 'UGG': 'W', 'CUU': 'L', 'CCU': 'P', 'CAU': 'H', 'CGU': 'R', 'CUC': 'L', 'CCC': 'P', 'CAC': 'H', 'CGC': 'R', 'CUA': 'L', 'CCA': 'P', 'CAA': 'Q', 'CGA': 'R', 'CUG': 'L', 'CCG': 'P', 'CAG': 'Q', 'CGG': 'R', 'AUU': 'I', 'ACU': 'T', 'AAU': 'N', 'AGU': 'S', 'AUC': 'I', 'ACC': 'T', 'AAC': 'N', 'AGC': 'S', 'AUA': 'I', 'ACA': 'T', 'AAA': 'K', 'AGA': 'R', 'AUG': 'M', 'ACG': 'T', 'AAG': 'K', 'AGG': 'R', 'GUU': 'V', 'GCU': 'A', 'GAU': 'D', 'GGU': 'G', 'GUC': 'V', 'GCC': 'A', 'GAC': 'D', 'GGC': 'G', 'GUA': 'V', 'GCA': 'A', 'GAA': 'E', 'GGA': 'G', 'GUG': 'V', 'GCG': 'A', 'GAG': 'E', 'GGG': 'G'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_data():\n",
    "    # URL of the HTML file to scrape\n",
    "    url = \"https://www.kazusa.or.jp/codon/cgi-bin/showcodon.cgi?species=9606&aa=1&style=N\"\n",
    "\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Extract the HTML content from the response\n",
    "        html_content = response.text\n",
    "        \n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Find the <pre> tag containing the codon table\n",
    "        pre_tag = soup.find('pre')\n",
    "\n",
    "        # Extract the text from the <pre> tag\n",
    "        codon_table_text = pre_tag.get_text()\n",
    "        \n",
    "        # Define the regular expression pattern to search for column names\n",
    "        pattern = r'fields:\\s*\\[triplet\\]\\s*\\[amino acid\\]\\s*\\[fraction\\]\\s*\\[frequency: <strong>per thousand</strong>\\]\\s*\\(\\[number\\]\\)'\n",
    "        \n",
    "        # Search for the pattern in the HTML content\n",
    "        match = re.search(pattern, html_content, re.IGNORECASE)\n",
    "        \n",
    "        \n",
    "        # Access the matched string instead of object\n",
    "        column_names = match.group()\n",
    "        \n",
    "        # Regular expression pattern to remove most extra charaters\n",
    "        pattern = r\"\\[(.*?)\\]\"\n",
    "\n",
    "        # Extracting the column names with out the charaters from above\n",
    "        matches = re.findall(pattern, column_names)\n",
    "\n",
    "        # Formatting the extracted column names to a list again\n",
    "        formatted_string = \" \".join(matches)\n",
    "        \n",
    "        # Remove HTML tags and format column names\n",
    "        formatted_string = re.sub(r'<.*?>', '', formatted_string)\n",
    "        \n",
    "        # Split the formatted string into a list of column names\n",
    "        formatted_list = formatted_string.split()\n",
    "        \n",
    "        # Create a substring for the frequency column to get it in the right format\n",
    "        new_sub = ' '.join([formatted_list[5], formatted_list[6]])\n",
    "        new_sub = ''. join([formatted_list[4][:-1], f\"({new_sub}):\"])\n",
    "        \n",
    "        # Combine the formatted column names to the final form\n",
    "        formatted_column = formatted_list[:4] + [new_sub] + formatted_list[-1:]\n",
    "\n",
    "    else:\n",
    "        # Print error message if request fails\n",
    "        print(\"Failed to retrieve HTML content. Status code:\", response.status_code)\n",
    "\n",
    "    # Return the formatted column names and codon table text\n",
    "    return formatted_column, codon_table_text\n",
    "\n",
    "    \n",
    "def get_dict():\n",
    "    # Get formatted column names and codon table text\n",
    "    column_names, codon_table = get_data()\n",
    "    \n",
    "    # Split the codon table text into rows\n",
    "    codon_rows = codon_table.split('\\n')\n",
    "    \n",
    "    # Remove whitespace\n",
    "    codon_rows = [row.strip() for row in codon_rows if row.strip()]\n",
    "\n",
    "    # Initialize an empty dictionary to store codon-amino acid pairs\n",
    "    codon_dict = {}\n",
    "    \n",
    "    # Extract the codon sequences and amino acids from each row\n",
    "    for row in codon_rows:\n",
    "        # Split the row into individual elements\n",
    "        elements = row.split()\n",
    "\n",
    "        # The values with a extra whitespace fx ( 63237) will create and extra value '(' in the list when doing.split()\n",
    "        # so we remove that extra \",\", because we dont use it any way\n",
    "        elements = [x for x in elements if x != '(']\n",
    "    \n",
    "        # Select the right elements for codon and amino acid\n",
    "        codon_sequence = elements[0]\n",
    "        amino_acid = elements[1]\n",
    "        codon_dict[codon_sequence] = amino_acid\n",
    "        \n",
    "        codon_sequence = elements[5]\n",
    "        amino_acid = elements[6]\n",
    "        codon_dict[codon_sequence] = amino_acid\n",
    "        \n",
    "        codon_sequence = elements[10]\n",
    "        amino_acid = elements[11]\n",
    "        codon_dict[codon_sequence] = amino_acid\n",
    "        \n",
    "        codon_sequence = elements[15]\n",
    "        amino_acid = elements[16]\n",
    "        codon_dict[codon_sequence] = amino_acid\n",
    "    \n",
    "    # Return the dictionary mapping codons to amino acids\n",
    "    return codon_dict\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    codon_to_aa = get_dict()\n",
    "    print(codon_to_aa)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "\"\"\"The idea is to get the wanted data from the webpage, by webscraping. The provided webpage was a copy, by entering the orginal webpage it made webscraping easier. After the wanted data is collected, it is being put on the right format, mostly the column names. Hower ever the column names are not being used in the get_dict function, and is more for purpos of understanding the columns. \n",
    "\n",
    "we manipulate the table from get_data function in get_dict. Here we split it into rows, and remove whitespace. Now we split each row into serpate values, and we append the wanted values to the dictionary. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "\"\"The solution works perfect, but the part with formatting and extracting the column names, are not strictly nessary in this solution. How ever for a dataset, with more unstructored data, the solution we accesing the wanted values based on their indicies may cause problems.\n",
    "\n",
    "The length of the dicionary is 64, wich also is the correct amount of codons\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use the same conversion table as above, but now write function `get_dict_list` to read the table into a `dict()`, such that for each amino acid the hash table stores the list of codons encoding it.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2073,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.882386Z",
     "start_time": "2019-07-08T22:04:22.872449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'F': ['UUU', 'UUC'], 'S': ['UCU', 'UCC', 'UCA', 'UCG', 'AGU', 'AGC'], 'Y': ['UAU', 'UAC'], 'C': ['UGU', 'UGC'], 'L': ['UUA', 'UUG', 'CUU', 'CUC', 'CUA', 'CUG'], '*': ['UAA', 'UGA', 'UAG'], 'W': ['UGG'], 'P': ['CCU', 'CCC', 'CCA', 'CCG'], 'H': ['CAU', 'CAC'], 'R': ['CGU', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG'], 'Q': ['CAA', 'CAG'], 'I': ['AUU', 'AUC', 'AUA'], 'T': ['ACU', 'ACC', 'ACA', 'ACG'], 'N': ['AAU', 'AAC'], 'K': ['AAA', 'AAG'], 'M': ['AUG'], 'V': ['GUU', 'GUC', 'GUA', 'GUG'], 'A': ['GCU', 'GCC', 'GCA', 'GCG'], 'D': ['GAU', 'GAC'], 'G': ['GGU', 'GGC', 'GGA', 'GGG'], 'E': ['GAA', 'GAG']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_dict_list():\n",
    "    previous_dict = get_dict()\n",
    "    # New dictionary\n",
    "    amino_acid_dict = {}\n",
    "    for key, value in previous_dict.items():\n",
    "        if not value in amino_acid_dict:\n",
    "            amino_acid_dict[value] = [key]\n",
    "        else:\n",
    "            amino_acid_dict[value].append(key)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return amino_acid_dict\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    aa_to_codons = get_dict_list()\n",
    "    print(aa_to_codons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "\"\"\"Using the result from the prevoius function, since it contain all the data we need, so we only need to orginize it differently. We creacte a new dictionart, and loop over both values and keys, and if the values not are in the dictionary they are added as a list. If that is false it means that the value is already there, and then we just need to append the new value to the new value list in the dictionary\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "\"\"\"The solution works well, when it is given a dictionary where codons are  keys and amino acid are values. By using .items() we can acess both at the same time in a loop. \n",
    "\n",
    "by typing return len(amino_acid_dict). we get 21, that is because * altso count, otherwise we have 20 different amino acid\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the conversion tables at hand, the following should be trivial to solve.\n",
    "\n",
    "4. Fill in function ```rna_to_prot``` in the stub solution to convert a given DNA sequence $s$ into a protein sequence. \n",
    "You may use the dictionaries from exercises 2 and 3. You can test your program with `ATGATATCATCGACGATGTAG`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2074,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.913321Z",
     "start_time": "2019-07-08T22:04:22.906646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSTM*\n"
     ]
    }
   ],
   "source": [
    "def rna_to_prot(s):\n",
    "    # Get the dictionary mapping RNA sequences to amino acids\n",
    "    rna_to_aa = get_dict()\n",
    "\n",
    "    # Split the RNA sequence into codons of length 3\n",
    "    codons = [s[i:i+3] for i in range(0, len(s), 3)]\n",
    "\n",
    "    # Convert each codon into its corresponding amino acid\n",
    "    protein_sequence = \"\"\n",
    "    for codon in codons:\n",
    "        # Check if the codon is in the dictionary\n",
    "        if codon in rna_to_aa:\n",
    "            amino_acid = rna_to_aa[codon]\n",
    "            protein_sequence += amino_acid\n",
    "        else:\n",
    "            # If the codon is not found, consider it as a stop codon\n",
    "            protein_sequence += \"*\"\n",
    "\n",
    "    return protein_sequence\n",
    "\n",
    "def dna_to_prot(s):\n",
    "    # Convert DNA sequence to RNA sequence\n",
    "    rna_sequence = dna_to_rna(s)\n",
    "    # Convert RNA sequence to protein sequence\n",
    "    protein_sequence = rna_to_prot(rna_sequence)\n",
    "    return protein_sequence\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(dna_to_prot(\"ATGATATCATCGACGATGTAG\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "\"\"\"get_dict_list() retrieves a dictionary that maps RNA codons to their corresponding amino acids.\n",
    "It utilizes the get_dict() function from Exercise 2 to obtain the initial dictionary.\n",
    "It then creates a new dictionary where the keys are amino acids and the values are lists of RNA codons that code for those amino acids.\n",
    "\n",
    "rna_to_prot(s) splits the RNA sequence into codons and looks up each codon in the conversion dictionary obtained from get_dict_list().\n",
    "For each codon, it retrieves the corresponding amino acid and appends it to the protein sequence.\n",
    "If we cant find the codon in the dictionary a * is append to the protein squence\n",
    "\n",
    "The last function is calling the functions for the final result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "The code seems to forfill the descired purpose. However it dont handle typing errors, but that was not given as a task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that there are $4^3=64$ different codons, but only 20 amino acids. That is, some triplets encode the same amino acid.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse translation\n",
    "\n",
    "It has been observed that among the codons coding the same amino acid, some are more frequent than others. These frequencies can be converted to probabilities. E.g. consider codons `AUU`, `AUC`, and `AUA` that code for amino acid isoleucine.\n",
    "If they are observed, say, 36, 47, 17 times, respectively, to code isoleucine in a dataset, the probability that a random such event is `AUU` $\\to$ isoleucine is 36/100.\n",
    "\n",
    "This phenomenon is called *codon adaptation*, and for our purposes it works as a good introduction to generation of random sequences under constraints.   \n",
    "\n",
    "5. Consider the codon adaptation frequencies in http://htmlpreview.github.io/?https://github.com/csmastersUH/data_analysis_with_python_2020/blob/master/Codon%20usage%20table.html and read them into a ```dict()```, such that for each RNA sequence of length 3, say `AGU`, the hash table stores the probability of that codon among codons encoding the same amino acid.\n",
    "Put your solution in the ```get_probabability_dict``` function. Use the column \"([number])\" to estimate the probabilities, as the two preceding columns contain truncated values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2075,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.966173Z",
     "start_time": "2019-07-08T22:04:22.956013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'UUU': 0.024639576199289373, 'UCU': 0.024567205044035097, 'UAU': 0.0246117099288076, 'UGU': 0.02463334657956687, 'UUC': 0.024615250299505755, 'UCC': 0.024621222659314608, 'UAC': 0.02458198574244827, 'UGC': 0.024560062998510802, 'UUA': 0.02468890378060863, 'UCA': 0.024574577800696145, 'UAA': 0.02482313516197096, 'UGA': 0.025301643025443965, 'UUG': 0.02453927044178296, 'UCG': 0.024523601179362274, 'UAG': 0.024915132828801895, 'UGG': 0.0246454877286009, 'CUU': 0.024603226377640886, 'CCU': 0.024536161394663455, 'CAU': 0.02467676829420141, 'CGU': 0.024375842997903675, 'CUC': 0.02460339577072648, 'CCC': 0.024607889438492705, 'CAC': 0.02460433459939744, 'CGC': 0.02455633317277269, 'CUA': 0.02476345739137613, 'CCA': 0.024562596833314437, 'CAA': 0.024506336780823694, 'CGA': 0.02472483649704897, 'CUG': 0.024568789819586913, 'CCG': 0.02450545157509678, 'CAG': 0.024569442079695514, 'CGG': 0.024543311409410424, 'AUU': 0.024597485214605374, 'ACU': 0.024549810816534203, 'AAU': 0.024648362116337367, 'AGU': 0.024522271694610572, 'AUC': 0.02457275306982206, 'ACC': 0.024604665513241603, 'AAC': 0.024594290776625897, 'AGC': 0.024640407994611962, 'AUA': 0.024625285242887398, 'ACA': 0.024571903736719372, 'AAA': 0.024556646850257793, 'AGA': 0.024662308311197898, 'AUG': 0.024553434411638327, 'ACG': 0.02478616850531277, 'AAG': 0.024622404999197264, 'AGG': 0.024667857576012975, 'GUU': 0.02452034854560896, 'GCU': 0.024530193468569356, 'GAU': 0.024620833516860192, 'GGU': 0.024706835100177068, 'GUC': 0.024654077784465548, 'GCC': 0.024563727798424903, 'GAC': 0.024593496930711986, 'GGC': 0.024569344762136645, 'GUA': 0.02467745523301079, 'GCA': 0.024554331119817367, 'GAA': 0.024625689519306538, 'GGA': 0.024631534634176923, 'GUG': 0.02457294667233331, 'GCG': 0.024708258902485854, 'GAG': 0.02459665522756565, 'GGG': 0.024635396137169883}\n",
      "AAA: 0.024557\tAAC: 0.024594\tAAG: 0.024622\tAAU: 0.024648\tACA: 0.024572\tACC: 0.024605\n",
      "ACG: 0.024786\tACU: 0.024550\tAGA: 0.024662\tAGC: 0.024640\tAGG: 0.024668\tAGU: 0.024522\n",
      "AUA: 0.024625\tAUC: 0.024573\tAUG: 0.024553\tAUU: 0.024597\tCAA: 0.024506\tCAC: 0.024604\n",
      "CAG: 0.024569\tCAU: 0.024677\tCCA: 0.024563\tCCC: 0.024608\tCCG: 0.024505\tCCU: 0.024536\n",
      "CGA: 0.024725\tCGC: 0.024556\tCGG: 0.024543\tCGU: 0.024376\tCUA: 0.024763\tCUC: 0.024603\n",
      "CUG: 0.024569\tCUU: 0.024603\tGAA: 0.024626\tGAC: 0.024593\tGAG: 0.024597\tGAU: 0.024621\n",
      "GCA: 0.024554\tGCC: 0.024564\tGCG: 0.024708\tGCU: 0.024530\tGGA: 0.024632\tGGC: 0.024569\n",
      "GGG: 0.024635\tGGU: 0.024707\tGUA: 0.024677\tGUC: 0.024654\tGUG: 0.024573\tGUU: 0.024520\n",
      "UAA: 0.024823\tUAC: 0.024582\tUAG: 0.024915\tUAU: 0.024612\tUCA: 0.024575\tUCC: 0.024621\n",
      "UCG: 0.024524\tUCU: 0.024567\tUGA: 0.025302\tUGC: 0.024560\tUGG: 0.024645\tUGU: 0.024633\n",
      "UUA: 0.024689\tUUC: 0.024615\tUUG: 0.024539\tUUU: 0.024640\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_probabability_dict():\n",
    "\n",
    "    # Get formatted column names and codon table text\n",
    "    column_names, codon_table = get_data()\n",
    "    \n",
    "    # Split the codon table text into rows\n",
    "    codon_rows = codon_table.split('\\n')\n",
    "    # Remove any empty rows\n",
    "    codon_rows = [row.strip() for row in codon_rows if row.strip()]\n",
    "    \n",
    "    # Initialize an empty dictionary to store codon adaptation probabilities\n",
    "    probability_dict = {}\n",
    "    \n",
    "    # Iterate over each row in the codon table\n",
    "    for row in codon_rows:\n",
    "        # Split the row into individual elements\n",
    "        elements = row.split()\n",
    "        elements = [x for x in elements if x != '(']\n",
    "        # Iterate over the elements with a step size of 5\n",
    "        for i in range(1, len(elements), 5):\n",
    "            codon_sequence = elements[i - 1]\n",
    "        \n",
    "            # handle that some values have ()\n",
    "            if \"(\" in elements[i + 3]:\n",
    "                number_value = elements[i + 3][1:-1]\n",
    "            else:\n",
    "                number_value = elements[i + 3][:-1]\n",
    "            \n",
    "            # Convert the number value to float and divide by 1000 to get the probability\n",
    "            probability = float(elements[i + 2]) / (float(number_value) / 1000)\n",
    "            \n",
    "    \n",
    "            probability_dict[codon_sequence] = probability\n",
    "            \n",
    "\n",
    "    return probability_dict\n",
    "if __name__ == '__main__':\n",
    "    codon_to_prob = get_probabability_dict()\n",
    "    print(codon_to_prob)\n",
    "    items = sorted(codon_to_prob.items(), key=lambda x: x[0])\n",
    "    for i in range(1 + len(items)//6):\n",
    "        print(\"\\t\".join(\n",
    "            f\"{k}: {v:.6f}\"\n",
    "            for k, v in items[i*6:6+i*6]\n",
    "            ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "Im unsure excaly how the possiblities is excepted to be calculated to, so i did the way i thought [frequency: per thousand]/([number]/1000). Again im a bit unsure exacly how you expect the output to be, an example would help. \n",
    "\n",
    "The Idea is to call the get_data function and use the data here from the values we want comes at a step of 5. with in the for loop we need to be aware of ( and () in the number values. When we have the values we want, we calculate the possibility using the formula above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "again we have the len of 64, and the values seems to be small, and in a realistic interval for possibilities. So it seems to work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should have everything in place to easily solve the following.\n",
    "\n",
    "\n",
    "6. Write a class ```ProteinToMaxRNA``` with a ```convert``` method which converts a protein sequence into the most likely RNA sequence to be the source of this protein. Run your program with `LTPIQNRA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2076,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.000743Z",
     "start_time": "2019-07-08T22:04:22.992108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUAACGCCCAUACAGAAUCGAGCG\n"
     ]
    }
   ],
   "source": [
    "class ProteinToMaxRNA:\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Initialize the necessary data structures\n",
    "        self.codon_to_prob = get_probabability_dict()\n",
    "        self.amino_acid_to_codons = get_dict_list()\n",
    "\n",
    "    def convert(self, s):\n",
    "        max_rna_sequence = \"\"\n",
    "        for amino_acid in s:\n",
    "            # Get the dictionary of codons for the current amino acid\n",
    "            codons_dict = self.amino_acid_to_codons.get(amino_acid)\n",
    "            if codons_dict:\n",
    "                # Find the codon with the highest probability\n",
    "                max_codon = max(codons_dict, key=lambda x: self.codon_to_prob.get(x, 0))\n",
    "                max_rna_sequence += max_codon\n",
    "            else:\n",
    "                # If the amino acid is not found, add a placeholder\n",
    "                max_rna_sequence += \"???\"\n",
    "        return max_rna_sequence\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    protein_to_rna = ProteinToMaxRNA()\n",
    "    print(protein_to_rna.convert(\"LTPIQNRA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "\"\"\"we Initialize the functions we need and there by getting the dictionary from them. We Loop over the RNA  and match it with the codon with the highest probability\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "The string \"LTPIQNRA\" is converted to CUAACGCCCAUACAGAAUCGAGCG based on the prevouis functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "For the amino acid \"L\", the most probable codon is \"CUA\" .\n",
    "For the amino acid \"T\", the most probable codon is \"ACC\".\n",
    "Etc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    "\n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "AACGUGAUUUC\n",
    "CUAACGCCCAUACAGAAUCGAGCG\n",
    "CUGACCCCCAUCCAGAACAGAGCC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are almost ready to produce random RNA sequences that code a given protein sequence. For this, we need a subroutine to *sample from a probability distribution*. Consider our earlier example of probabilities 36/100, 47/100, and 17/100 for `AUU`, `AUC`, and `AUA`, respectively. \n",
    "Let us assume we have a random number generator ```random()``` that returns a random number from interval $[0,1)$. We may then partition the unit interval according to cumulative probabilities to $[0,36/100), [36/100,83/100), [83/100,1)$, respectively. Depending which interval the number ```random()``` hits, we select the codon accordingly.\n",
    "\n",
    "7. Write a function ```random_event``` that chooses a random event, given a probability distribution (set of events whose probabilities sum to 1).\n",
    "You can use function ```random.uniform``` to produce values uniformly at random from the range $[0,1)$. The distribution should be given to your function as a dictionary from events to their probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.036655Z",
     "start_time": "2019-07-08T22:04:23.030067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C, T, C, C, T, C, C, G, G, A, C, T, C, T, T, T, C, C, T, T, T, C, T, T, C, T, C, G, T\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def random_event(dist):\n",
    "    \"\"\"\n",
    "    Takes as input a dictionary from events to their probabilities.\n",
    "    Return a random event sampled according to the given distribution.\n",
    "    The probabilities must sum to 1.0\n",
    "    \"\"\"\n",
    "    # Ensure the probabilities sum up to 1.0\n",
    "    total_prob = sum(dist.values())\n",
    "    if total_prob != 1.0:\n",
    "        raise ValueError(\"Probabilities must sum up to 1.0\")\n",
    "    \n",
    "    # Generate a random number between 0 and 1\n",
    "    rand_num = random.random()\n",
    "    \n",
    "    # Iterate through the events and their probabilities\n",
    "    cumulative_prob = 0\n",
    "    for event, prob in dist.items():\n",
    "        cumulative_prob += prob\n",
    "        if rand_num <= cumulative_prob:\n",
    "            return event\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    distribution = dict(zip(\"ACGT\", [0.10, 0.35, 0.15, 0.40]))\n",
    "    print(\", \".join(random_event(distribution) for _ in range(29)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "returns:\n",
    "C, C, C, C, T, T, C, A, C, G, C, T, T, C, C, C, G, A, T, T, C, T, G, T, T, T, C, T, T\n",
    "\n",
    "our function takes a probability distribution as a dictionary from events to their probabilities, and it uses random.uniform to produce values uniformly at random from the range $[0,1)$. The function then partitions the unit interval according to cumulative probabilities and selects the event accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "we could also have used numpys np.choice method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this general routine, the following should be easy to solve.\n",
    " \n",
    "8. Write a class ```ProteinToRandomRNA``` to produce a random RNA sequence encoding the input protein sequence according to the input codon adaptation probabilities. The actual conversion is done through the ```convert``` method. Run your program with `LTPIQNRA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.073660Z",
     "start_time": "2019-07-08T22:04:23.067966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UUAACUCCUAUUCAAAAUAGGGCG\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class ProteinToRandomRNA:\n",
    "    def __init__(self, codon_probs, aa_to_rna):\n",
    "        self.codon_probs = codon_probs\n",
    "        self.aa_to_rna = aa_to_rna\n",
    "\n",
    "    def convert(self, protein_sequence):\n",
    "        rna_sequence = \"\"\n",
    "        for amino_acid in protein_sequence:\n",
    "            if amino_acid in self.aa_to_rna:\n",
    "                codons = self.aa_to_rna[amino_acid]\n",
    "                chosen_codon = random.choices(codons, weights=[self.codon_probs[codon] for codon in codons])[0]\n",
    "                rna_sequence += chosen_codon\n",
    "            else:\n",
    "                rna_sequence += \"???\"\n",
    "        return rna_sequence\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # from get_probabability_dict()\n",
    "    CODON_PROBS = {\n",
    "        'UUU': 0.024639576199289373, 'UCU': 0.024567205044035097, 'UAU': 0.0246117099288076, 'UGU': 0.02463334657956687, \n",
    "        'UUC': 0.024615250299505755, 'UCC': 0.024621222659314608, 'UAC': 0.02458198574244827, 'UGC': 0.024560062998510802, \n",
    "        'UUA': 0.02468890378060863, 'UCA': 0.024574577800696145, 'UAA': 0.02482313516197096, 'UGA': 0.025301643025443965, \n",
    "        'UUG': 0.02453927044178296, 'UCG': 0.024523601179362274, 'UAG': 0.024915132828801895, 'UGG': 0.0246454877286009, \n",
    "        'CUU': 0.024603226377640886, 'CCU': 0.024536161394663455, 'CAU': 0.02467676829420141, 'CGU': 0.024375842997903675, \n",
    "        'CUC': 0.02460339577072648, 'CCC': 0.024607889438492705, 'CAC': 0.02460433459939744, 'CGC': 0.02455633317277269, \n",
    "        'CUA': 0.02476345739137613, 'CCA': 0.024562596833314437, 'CAA': 0.024506336780823694, 'CGA': 0.02472483649704897, \n",
    "        'CUG': 0.024568789819586913, 'CCG': 0.02450545157509678, 'CAG': 0.024569442079695514, 'CGG': 0.024543311409410424, \n",
    "        'AUU': 0.024597485214605374, 'ACU': 0.024549810816534203, 'AAU': 0.024648362116337367, 'AGU': 0.024522271694610572, \n",
    "        'AUC': 0.02457275306982206, 'ACC': 0.024604665513241603, 'AAC': 0.024594290776625897, 'AGC': 0.024640407994611962, \n",
    "        'AUA': 0.024625285242887398, 'ACA': 0.024571903736719372, 'AAA': 0.024556646850257793, 'AGA': 0.024662308311197898, \n",
    "        'AUG': 0.024553434411638327, 'ACG': 0.02478616850531277, 'AAG': 0.024622404999197264, 'AGG': 0.024667857576012975, \n",
    "        'GUU': 0.02452034854560896, 'GCU': 0.024530193468569356, 'GAU': 0.024620833516860192, 'GGU': 0.024706835100177068, \n",
    "        'GUC': 0.024654077784465548, 'GCC': 0.024563727798424903, 'GAC': 0.024593496930711986, 'GGC': 0.024569344762136645, \n",
    "        'GUA': 0.02467745523301079, 'GCA': 0.024554331119817367, 'GAA': 0.024625689519306538, 'GGA': 0.024631534634176923, \n",
    "        'GUG': 0.02457294667233331, 'GCG': 0.024708258902485854, 'GAG': 0.02459665522756565, 'GGG': 0.024635396137169883\n",
    "    }\n",
    "    # from get_dict_list()\n",
    "    AA_TO_RNA = {\n",
    "        'F': ['UUU', 'UUC'], 'S': ['UCU', 'UCC', 'UCA', 'UCG', 'AGU', 'AGC'], 'Y': ['UAU', 'UAC'], 'C': ['UGU', 'UGC'], \n",
    "        'L': ['UUA', 'UUG', 'CUU', 'CUC', 'CUA', 'CUG'], '*': ['UAA', 'UGA', 'UAG'], 'W': ['UGG'], 'P': ['CCU', 'CCC', \n",
    "        'CCA', 'CCG'], 'H': ['CAU', 'CAC'], 'R': ['CGU', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG'], 'Q': ['CAA', 'CAG'], 'I': \n",
    "        ['AUU', 'AUC', 'AUA'], 'T': ['ACU', 'ACC', 'ACA', 'ACG'], 'N': ['AAU', 'AAC'], 'K': ['AAA', 'AAG'], 'M': ['AUG'], \n",
    "        'V': ['GUU', 'GUC', 'GUA', 'GUG'], 'A': ['GCU', 'GCC', 'GCA', 'GCG'], 'D': ['GAU', 'GAC'], \n",
    "        'G': ['GGU', 'GGC', 'GGA', 'GGG'], 'E': ['GAA', 'GAG']\n",
    "    }\n",
    "\n",
    "    protein_to_random_codons = ProteinToRandomRNA(CODON_PROBS, AA_TO_RNA)\n",
    "    print(protein_to_random_codons.convert(\"LTPIQNRA\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "We use the results of the prevouis functions to help make hte rna sequence.\n",
    "convert method iterates over each amino acid in the input protein sequence. For each amino acid, it randomly selects a codon based on the probabilities specified in codon_probs and aa_to_rna. The selected codon is then added to the RNA sequence, starting at an empty string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "The output is UUAACUCCUAUUCAAAAUAGGGCG, wich look like it could be the right solution. But without much guidence it is hard to tell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating DNA sequences with higher-order Markov chains\n",
    "\n",
    "We will now reuse the machinery derived above in a related context. We go back to DNA sequences, and consider some easy statistics that can be used to characterize the sequences. \n",
    "First, just the frequencies of bases $\\texttt{A}$, $\\texttt{C}$, $\\texttt{G}$, $\\texttt{T}$ may reveal the species from which the input DNA originates; each species has a different base composition that has been formed during evolution. \n",
    "More interestingly, the areas where DNA to RNA transcription takes place (coding region) have an excess of $\\texttt{C}$ and $\\texttt{G}$ over $\\texttt{A}$ and $\\texttt{T}$. To detect such areas a common routine is to just use a *sliding window* of fixed size, say $k$, and compute for each window position \n",
    "$T[i..i+k-1]$ the base frequencies, where $T[1..n]$ is the input DNA sequence. When sliding the window from  $T[i..i+k-1]$ to $T[i+1..i+k]$ frequency $f(T[i])$ gets decreases by one and $f(T[i+k])$ gets increased by one. \n",
    "\n",
    "9. Write a *generator* ```sliding_window``` to compute sliding window base frequencies so that each moving of the window takes constant time. We saw in the beginning of the course one way how to create generators using\n",
    "  generator expression. Here we use a different way. For the function ```sliding_window``` to be a generator, it must have at least   one ```yield``` expression, see [https://docs.python.org/3/reference/expressions.html#yieldexpr](https://docs.python.org/3/reference/expressions.html#yieldexpr).\n",
    "  \n",
    "  Here is an example of a generator expression that works similarily to the built in `range` generator:\n",
    "  ```Python\n",
    "  def range(a, b=None, c=1):\n",
    "      current = 0 if b == None else a\n",
    "      end = a if b == None else b\n",
    "      while current < end:\n",
    "          yield current\n",
    "          current += c\n",
    "  ```\n",
    "  A yield expression can be used to return a value and *temporarily* return from the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2287,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.111365Z",
     "start_time": "2019-07-08T22:04:23.100858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'C': 2, 'G': 2, 'T': 0}\n",
      "{'A': 0, 'C': 2, 'G': 1, 'T': 1}\n",
      "{'A': 1, 'C': 1, 'G': 1, 'T': 1}\n",
      "{'A': 1, 'C': 2, 'G': 0, 'T': 1}\n",
      "{'A': 1, 'C': 1, 'G': 1, 'T': 1}\n",
      "{'A': 2, 'C': 1, 'G': 1, 'T': 0}\n",
      "{'A': 1, 'C': 1, 'G': 1, 'T': 1}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 1, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 1, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 1, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 1, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n",
      "{'A': 0, 'C': 0, 'G': 0, 'T': 0}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "BASE = 'ACGT'\n",
    "\n",
    "def sliding_window(s, k):\n",
    "    \"\"\"This function returns a generator that can be iterated over all\n",
    "    starting positions of a k-window in the sequence.\n",
    "    For each starting position, the generator returns the nucleotide frequencies\n",
    "    in the window as a dictionary.\"\"\"\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    while i + k <= len(s):\n",
    "        ka = s[i:i+k]\n",
    "        \n",
    "        \n",
    "        letter_freq = {}\n",
    "        for nucleotide in BASE:\n",
    "            count = ka.count(nucleotide)\n",
    "            letter_freq[nucleotide] = count\n",
    "        \n",
    "        yield letter_freq\n",
    "        i += 1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for d in sliding_window('GCGCTACGAT', 4):\n",
    "        print(d)\n",
    "    for s in sys.argv[1:]:\n",
    "        for d in sliding_window(s, 4):\n",
    "            print(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "My function sliding_window generates nucleotide frequencies for each k-length substring as it moves along the input sequence. It starts at the beginning of the sequence and iterates through it, considering each window of length k. Within each window, it counts the occurrences of each nucleotide and yields these frequencies as a dictionary. This approach allows for memory-efficient processing of large sequences, providing nucleotide frequencies one window at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "The top output:\n",
    "{'A': 0, 'C': 2, 'G': 2, 'T': 0}\n",
    "{'A': 0, 'C': 2, 'G': 1, 'T': 1}\n",
    "{'A': 1, 'C': 1, 'G': 1, 'T': 1}\n",
    "{'A': 1, 'C': 2, 'G': 0, 'T': 1}\n",
    "{'A': 1, 'C': 1, 'G': 1, 'T': 1}\n",
    "{'A': 2, 'C': 1, 'G': 1, 'T': 0}\n",
    "{'A': 1, 'C': 1, 'G': 1, 'T': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "Our models so far have been so-called *zero-order* models, as each event has been independent of other events. With sequences, the dependencies of events are naturally encoded by their *contexts*. Considering that a sequence is produced from left-to-right, a *first-order* context for $T[i]$ is $T[i-1]$, that is, the immediately preceding symbol. *First-order Markov chain* is a sequence produced by generating $c=T[i]$ with the probability of event of seeing symbol $c$ after previously generated symbol $a=T[i-1]$. The first symbol of the chain is sampled according to the zero-order model.  \n",
    "The first-order model can naturally be extended to contexts of length $k$, with $T[i]$ depending on $T[i-k..i-1]$. Then the first $k$ symbols of the chain are sampled according to the zero-order model.  The following assignments develop the routines to work with the *higher-order Markov chains*. \n",
    "In what follows, a $k$-mer is a substring $T[i..i+k-1]$ of the sequence at an arbitrary position. \n",
    "\n",
    "10. Write function ```context_list``` that given an input DNA sequence $T$ associates to each $k$-mer $W$ the concatenation of all symbols $c$ that appear after context $W$ in $T$, that is, $T[i..i+k]=Wc$. For example, <span style=\"color:red; font:courier;\">GA</span> is associated to <span style=\"color:blue; font: courier;\">TCT</span> in $T$=<span style=\"font: courier;\">AT<span style=\"color:red;\">GA</span><span style=\"color:blue;\">T</span>ATCATC<span style=\"color:red;\">GA</span><span style=\"color:blue;\">C</span><span style=\"color:red;\">GA</span><span style=\"color:blue;\">T</span>GTAG</span>, when $k=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2327,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.168108Z",
     "start_time": "2019-07-08T22:04:23.162648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AT': 'GACCC', 'TG': 'A', 'GA': 'TCT', 'TA': 'TG', 'TC': 'AGT', 'CA': 'T', 'CG': 'AA', 'AC': 'G', 'CT': 'A'}\n"
     ]
    }
   ],
   "source": [
    "def context_list(s, k):\n",
    "    contexts = {}\n",
    "    for i in range(len(s) - k):\n",
    "        ka = s[i:i+k]\n",
    "        next_symbol = s[i+k]\n",
    "        if ka in contexts:\n",
    "            contexts[ka] += next_symbol\n",
    "        else:\n",
    "            contexts[ka] = next_symbol\n",
    "    return contexts\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    s = \"ATGATATCATCGACGATCTAG\"\n",
    "    d = context_list(s, k)\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "My function context_list generates a dictionary associating each k-mer in the input DNA sequence with the symbols that follow it. It starts at the beginning of the sequence and iterates through it, considering each k-mer of length k. For each k-mer encountered, it records the symbol that immediately follows it in the sequence. If the k-mer is already present in the dictionary, the following symbol is appended to the existing list of symbols associated with that k-mer. If the k-mer is not already in the dictionary, a new entry is created with the k-mer as the key and the following symbol as the associated value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "when k = 2\n",
    "    s = \"ATGATATCATCGACGATCTAG\"\n",
    "    d = context_list(s, k)\n",
    "    the output is\n",
    "{'AT': 'GACCC', 'TG': 'A', 'GA': 'TCT', 'TA': 'TG', 'TC': 'AGT', 'CA': 'T', 'CG': 'AA', 'AC': 'G', 'CT': 'A'}Â¨\n",
    "\n",
    "The k-mer 'AT' appears twice in the sequence at positions 0 and 3, with following symbols 'GACCC'.\n",
    "Similarly, for other k-mers like 'TG', 'GA', 'TA', 'TC', 'CA', 'CG', 'AC', and 'CT', their following symbols are recorded accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. With the above solution, write function ```context_probabilities``` to count the frequencies of symbols in each context and convert these frequencies into probabilities. Run `context_probabilities` with $T=$ `ATGATATCATCGACGATGTAG` and $k$ values 0 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2364,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.218964Z",
     "start_time": "2019-07-08T22:04:23.213773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AT': {'G': 0.4, 'A': 0.2, 'C': 0.4}, 'TG': {'A': 0.5, 'T': 0.5}, 'GA': {'T': 0.6666666666666666, 'C': 0.3333333333333333}, 'TA': {'T': 0.5, 'G': 0.5}, 'TC': {'A': 0.5, 'G': 0.5}, 'CA': {'T': 1.0}, 'CG': {'A': 1.0}, 'AC': {'G': 1.0}, 'GT': {'A': 1.0}}\n",
      "{'': {'A': 0.3333333333333333, 'T': 0.2857142857142857, 'G': 0.23809523809523808, 'C': 0.14285714285714285}}\n"
     ]
    }
   ],
   "source": [
    "def context_probabilities(s, k):\n",
    "    \"\"\"\n",
    "    Counts the frequencies of symbols in each context and converts these frequencies into probabilities.\n",
    "\n",
    "    Args:\n",
    "    - s (str): Input DNA sequence\n",
    "    - k (int): Length of the k-mer\n",
    "    \"\"\"\n",
    "    # Generate the context list\n",
    "    contexts = context_list(s, k)\n",
    "    \n",
    "    # Calculate symbol frequencies in each context\n",
    "    context_prob = {}\n",
    "    for context, following_symbols in contexts.items():\n",
    "        symbol_freq = {}\n",
    "        for symbol in following_symbols:\n",
    "            symbol_freq[symbol] = symbol_freq.get(symbol, 0) + 1\n",
    "        total_symbols = sum(symbol_freq.values())\n",
    "        \n",
    "        # Convert frequencies to probabilities\n",
    "        symbol_prob = {symbol: freq / total_symbols for symbol, freq in symbol_freq.items()}\n",
    "        context_prob[context] = symbol_prob\n",
    "    \n",
    "    return context_prob\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    a=context_probabilities(\"ATGATATCATCGACGATGTAG\", 2)\n",
    "    print(a)\n",
    "    b = context_probabilities(\"ATGATATCATCGACGATGTAG\", 0)\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "My function context_probabilities function aims to calculate the probabilities of observing each symbol in a context of length k within the input DNA sequence. It achieves this by first generating the contexts using the context_list function. Then, for each context, it counts the frequencies of symbols that follow that context. These frequencies are then converted into probabilities by dividing each frequency by the total number of symbols observed after the context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "With a=context_probabilities(\"ATGATATCATCGACGATGTAG\", 2)\n",
    "the output is\n",
    "{'AT': {'G': 0.4, 'A': 0.2, 'C': 0.4}, 'TG': {'A': 0.5, 'T': 0.5}, 'GA': {'T': 0.6666666666666666,\n",
    " 'C': 0.3333333333333333}, 'TA': {'T': 0.5, 'G': 0.5}, 'TC': {'A': 0.5, 'G': 0.5}, 'CA': {'T': 1.0},\n",
    "  'CG': {'A': 1.0}, 'AC': {'G': 1.0}, 'GT': {'A': 1.0}}\n",
    "\n",
    "with context_probabilities(\"ATGATATCATCGACGATGTAG\", 0)\n",
    "{'': {'A': 0.3333333333333333, 'T': 0.2857142857142857, 'G': 0.23809523809523808, 'C': 0.14285714285714285}}\n",
    "\n",
    "My function function uses nested loops to calculate frequencies and probabilities, which may not be efficient for large sequences or contexts with many unique symbols. The function assumes that the input sequence contains valid DNA symbols and handles only contexts of length k. It does not account for cases such as empty sequences or incorrect inputs, which could lead to unexpected behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. With the above solution and the function ```random_event``` from the earlier exercise, write class ```MarkovChain```. Its ```generate``` method should generate a random DNA sequence following the original $k$-th order Markov chain probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2380,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.279315Z",
     "start_time": "2019-07-08T22:04:23.253983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TGTATGATGA\n"
     ]
    }
   ],
   "source": [
    "class MarkovChain:\n",
    "    \n",
    "    def __init__(self, zeroth, kth, k=2):\n",
    "        self.k = k\n",
    "        self.zeroth = zeroth\n",
    "        self.kth = kth\n",
    "        \n",
    "    def generate(self, n, seed=None):\n",
    "        random.seed(seed)\n",
    "        sequence = \"\"\n",
    "        current_context = \"$\" * self.k  # Start with context of length k\n",
    "        for _ in range(n):\n",
    "            if current_context in self.kth:\n",
    "                next_symbol = random_event(self.kth[current_context])\n",
    "            else:\n",
    "                next_symbol = random_event(self.zeroth)\n",
    "            sequence += next_symbol\n",
    "            current_context = current_context[1:] + next_symbol\n",
    "        return sequence\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    zeroth = {'A': 0.2, 'C': 0.19, 'T': 0.31, 'G': 0.3}\n",
    "    kth = {'GT': {'A': 1.0, 'C': 0.0, 'T': 0.0, 'G': 0.0},\n",
    "           'CA': {'A': 0.0, 'C': 0.0, 'T': 1.0, 'G': 0.0},\n",
    "           'TC': {'A': 0.5, 'C': 0.0, 'T': 0.0, 'G': 0.5},\n",
    "           'GA': {'A': 0.0, 'C': 0.3333333333333333, 'T': 0.6666666666666666, 'G': 0.0},\n",
    "           'TG': {'A': 0.5, 'C': 0.0, 'T': 0.5, 'G': 0.0},\n",
    "           'AT': {'A': 0.2, 'C': 0.4, 'T': 0.0, 'G': 0.4},\n",
    "           'TA': {'A': 0.0, 'C': 0.0, 'T': 0.5, 'G': 0.5},\n",
    "           'AC': {'A': 0.0, 'C': 0.0, 'T': 0.0, 'G': 1.0},\n",
    "           'CG': {'A': 1.0, 'C': 0.0, 'T': 0.0, 'G': 0.0}}\n",
    "    n = 10    \n",
    "    seed = 0\n",
    "    mc = MarkovChain(zeroth, kth)\n",
    "    print(mc.generate(n, seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "The constructor is initialized with the zeroth-order probabilities (zeroth) and the k-th order probabilities (kth). The parameter k specifies the order of the Markov chain, with a default value of 2.\n",
    "\n",
    "My generator method generates a random DNA sequence of length n based on the provided probabilities. It starts by setting an initial context of length k as \"$\" (or any other symbol not present in the original sequence). Then, for each position in the generated sequence, it randomly selects the next symbol based on the current context and the associated probabilities. The context is updated by shifting one position to the right and appending the newly selected symbol. This process continues until the desired sequence length is reached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "with the given information in __main__\n",
    "output:TGTATGATGA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have survived so far without problems, please run your program a few more times with different inputs. At some point you should get a lookup error in your hash-table! The reason for this is not your code, but the way we defined the model: Some $k$-mers may not be among the training data (input sequence $T$), but such can be generated as the first $k$-mer that is generated using the zero-order model.  \n",
    "\n",
    "A general approach to fixing such issues with incomplete training data is to use *pseudo counts*. That is, all imaginable events are initialized to frequency count 1.   \n",
    "\n",
    "13. Write a new solution `context_pseudo_probabilities` based on the solution to problem 11. But this time use pseudo counts in order to obtain a $k$-th order Markov chain that can assign a probability for any DNA sequence. You may use the standard library function `itertools.product` to iterate over all $k$-mer of given length (`product(\"ACGT\", repeat=k)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2382,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.303566Z",
     "start_time": "2019-07-08T22:04:23.296028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeroth: {'A': 0.3333333333333333, 'T': 0.2857142857142857, 'G': 0.23809523809523808, 'C': 0.14285714285714285}\n",
      "AT: {'G': 0.4, 'A': 0.2, 'C': 0.4}\n",
      "TG: {'A': 0.5, 'T': 0.5}\n",
      "GA: {'T': 0.6666666666666666, 'C': 0.3333333333333333}\n",
      "TA: {'T': 0.5, 'G': 0.5}\n",
      "TC: {'A': 0.5, 'G': 0.5}\n",
      "CA: {'T': 1.0}\n",
      "CG: {'A': 1.0}\n",
      "AC: {'G': 1.0}\n",
      "GT: {'A': 1.0}\n",
      "AA: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "AG: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "CC: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "CT: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "GC: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "GG: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "TT: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "\n",
      " GTAGATGTAGTATCATGTAT\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def context_pseudo_probabilities(s, k):\n",
    "    kth = {}\n",
    "    n = len(s)\n",
    "    all_kmers = [''.join(kmer) for kmer in itertools.product(\"ACGT\", repeat=k)]\n",
    "    \n",
    "    for i in range(n - k):\n",
    "        kmer = s[i:i+k]\n",
    "        next_n = s[i+k]\n",
    "        if kmer in kth:\n",
    "            kth[kmer][next_n] = kth[kmer].get(next_n, 0) + 1\n",
    "        else:\n",
    "            kth[kmer] = {next_n: 1}\n",
    "    \n",
    "    # Add pseudo counts for missing k-mers\n",
    "    for kmer in all_kmers:\n",
    "        if kmer not in kth:\n",
    "            kth[kmer] = {'A': 1, 'C': 1, 'G': 1, 'T': 1}\n",
    "    \n",
    "    # Convert counts to probabilities\n",
    "    for kmer, counts in kth.items():\n",
    "        total_count = sum(counts.values())\n",
    "        kth[kmer] = {nucleotide: count / total_count for nucleotide, count in counts.items()}\n",
    "    \n",
    "    return kth\n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    s = \"ATGATATCATCGACGATGTAG\"\n",
    "    kth = context_pseudo_probabilities(s, k)\n",
    "    zeroth = context_pseudo_probabilities(s, 0)[\"\"]\n",
    "    print(f\"zeroth: {zeroth}\")\n",
    "    print(\"\\n\".join(f\"{k}: {dict(v)}\" for k, v in kth.items()))\n",
    "    \n",
    "    print(\"\\n\", MarkovChain(zeroth, kth, k).generate(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "Seems to do what it is suppose to do, with itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "the first printout with the given values in main:\n",
    "zeroth: {'A': 0.3333333333333333, 'T': 0.2857142857142857, 'G': 0.23809523809523808, 'C': 0.14285714285714285}\n",
    "AT: {'G': 0.4, 'A': 0.2, 'C': 0.4}\n",
    "TG: {'A': 0.5, 'T': 0.5}\n",
    "GA: {'T': 0.6666666666666666, 'C': 0.3333333333333333}\n",
    "TA: {'T': 0.5, 'G': 0.5}\n",
    "TC: {'A': 0.5, 'G': 0.5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Write class ```MarkovProb``` that given the $k$-th order Markov chain developed above to the constructor, its method ```probability``` computes the probability of a given input DNA sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2411,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.346222Z",
     "start_time": "2019-07-08T22:04:23.330779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of sequence ATGATATCATCGACGATGTAG is 1.1851851851851853e-05\n",
      "Probability of sequence ATG is 0.4\n",
      "Probability of sequence AC is 1.0\n",
      "Probability of sequence ACGT is 0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MarkovChain:\n",
    "    def __init__(self, k, zeroth, kth):\n",
    "        self.k = k\n",
    "        self.zeroth = zeroth\n",
    "        self.kth = kth\n",
    "\n",
    "    def probability(self, s):\n",
    "        prob = 1.0\n",
    "        for i in range(len(s) - self.k):\n",
    "            kmer = s[i:i+self.k]\n",
    "            next_n = s[i+self.k]\n",
    "            prob *= self.kth.get(kmer, {}).get(next_n, self.zeroth[next_n])\n",
    "        return prob\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    # Result from previous exercise\n",
    "    zeroth = {'A': 0.3333333333333333, 'T': 0.2857142857142857, 'G': 0.23809523809523808, 'C': 0.14285714285714285}\n",
    "    kth = {'AT': {'G': 0.4, 'A': 0.2, 'C': 0.4},\n",
    "           'TG': {'A': 0.5, 'T': 0.5},\n",
    "           'GA': {'T': 0.6666666666666666, 'C': 0.3333333333333333},\n",
    "           'TA': {'T': 0.5, 'G': 0.5},\n",
    "           'TC': {'A': 0.5, 'G': 0.5},\n",
    "           'CA': {'T': 1.0},\n",
    "           'CG': {'A': 1.0},\n",
    "           'AC': {'G': 1.0},\n",
    "           'GT': {'A': 1.0},\n",
    "           'AA': {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25},\n",
    "           'AG': {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25},\n",
    "           'CC': {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25},\n",
    "           'CT': {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25},\n",
    "           'GC': {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25},\n",
    "           'GG': {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25},\n",
    "           'TT': {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}}\n",
    "    mc = MarkovChain(k, zeroth, kth)\n",
    "    sequences = [\"ATGATATCATCGACGATGTAG\", \"ATG\", \"AC\", \"ACGT\"]\n",
    "    for seq in sequences:\n",
    "        print(f\"Probability of sequence {seq} is {mc.probability(seq)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "My class takes as input the order of the Markov chain (k), the zeroth order probabilities (zeroth), and the transition probabilities for each k-mer (kth). The class provides a method probability that calculates the probability of a given DNA sequence based on the Markov chain model. The code then initializes an instance of the MarkovChain class with provided zeroth order and transition probabilities and computes the probabilities for a list of input DNA sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "Probability of sequence ATGATATCATCGACGATGTAG is 1.1851851851851853e-05\n",
    "Probability of sequence ATG is 0.4\n",
    "Probability of sequence AC is 1.0\n",
    "Probability of sequence ACGT is 0.2857142857142857"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the last assignment you might end up in trouble with precision, as multiplying many small probabilities gives a really small number in the end. There is an easy fix by using so-called log-transform. \n",
    "Consider computation of $P=s_1 s_2 \\cdots s_n$, where $0\\leq s_i\\leq 1$ for each $i$. Taking logarithm in base 2 from both sides gives $\\log _2 P= \\log _2 (s_1 s_2 \\cdots s_n)=\\log_2 s_1 + \\log_2 s_2 + \\cdots \\log s_n= \\sum_{i=1}^n \\log s_i$, with repeated application of the property that the logarithm of a multiplication of two numbers is the sum of logarithms of the two numbers taken separately. The results is abbreviated as log-probability.\n",
    "\n",
    "15. Write class ```MarkovLog``` that given the $k$-th order Markov chain developed above to the constructor, its method ```log_probability``` computes the log-probability of a given input DNA sequence. Run your program with $T=$ `ATGATATCATCGACGATGTAG` and $k=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2436,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.390453Z",
     "start_time": "2019-07-08T22:04:23.379760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log probability of sequence ATGATATCATCGACGATGTAG is -16.36452797660028\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MarkovLog(object):\n",
    "\n",
    "    def __init__(self, k, zeroth, kth):\n",
    "        self.k = k\n",
    "        self.zeroth = zeroth\n",
    "        self.kth = kth\n",
    "\n",
    "    def log_probability(self, s):\n",
    "        log_prob = 0.0\n",
    "        for i in range(len(s) - self.k):\n",
    "            kmer = s[i:i+self.k]\n",
    "            next_n = s[i+self.k]\n",
    "            prob = self.kth.get(kmer, {}).get(next_n, self.zeroth[next_n])\n",
    "            log_prob += np.log2(prob)\n",
    "        return log_prob\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    kth = context_pseudo_probabilities(\"ATGATATCATCGACGATGTAG\", k)\n",
    "    zeroth = context_pseudo_probabilities(\"ATGATATCATCGACGATGTAG\", 0)[\"\"]\n",
    "    mc = MarkovLog(2, zeroth, kth)\n",
    "    s=\"ATGATATCATCGACGATGTAG\"\n",
    "    print(f\"Log probability of sequence {s} is {mc.log_probability(s)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "my class consider the conditional probabilities of observing each nucleotide given the preceding k-mer (a substring of length k) in the sequence. For each k-mer observed in the input data, my model calculates the probability of observing each possible nucleotide as the next symbol in the sequence. These probabilities are stored in the kth dictionary.\n",
    "Additionally, the model also considers the probabilities of observing the first symbol in the sequence based on the zeroth order model, which are stored in the zeroth dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "Log probability of sequence ATGATATCATCGACGATGTAG is -16.36452797660028\n",
    "\n",
    "The output -16.36452797660028 represents the log probability of the sequence \"ATGATATCATCGACGATGTAG\" according to the Markov chain model defined by the provided zeroth order and transition probabilities. This value indicates the likelihood of observing the given sequence under the model.\n",
    "\n",
    "Since log probabilities are negative, a smaller absolute value indicates a higher probability. In this case, the log probability is relatively large in magnitude, indicating that the sequence is less likely to occur according to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if you try to use the code so far for very large inputs, you might observe that the concatenation of symbols following a context occupy considerable amount of space. This is unnecessary, as we only need the frequencies. \n",
    "\n",
    "16. Optimize the space requirement of your code from exercise 13 for the $k$-th order Markov chain by replacing the concatenations by direct computations of the frequencies. Implement this as the\n",
    "  ```better_context_probabilities``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2452,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.422302Z",
     "start_time": "2019-07-08T22:04:23.416330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AT: {'G': 2, 'A': 1, 'C': 2}\n",
      "TG: {'A': 1, 'T': 1}\n",
      "GA: {'T': 2, 'C': 1}\n",
      "TA: {'T': 1, 'G': 1}\n",
      "TC: {'A': 1, 'G': 1}\n",
      "CA: {'T': 1}\n",
      "CG: {'A': 2}\n",
      "AC: {'G': 1}\n",
      "GT: {'A': 1}\n"
     ]
    }
   ],
   "source": [
    "def better_context_probabilities(s, k):\n",
    "    contexts = {}\n",
    "    for i in range(len(s) - k):\n",
    "        ka = s[i:i+k]\n",
    "        next_symbol = s[i+k]\n",
    "        if ka in contexts:\n",
    "            if next_symbol in contexts[ka]:\n",
    "                contexts[ka][next_symbol] += 1\n",
    "            else:\n",
    "                contexts[ka][next_symbol] = 1\n",
    "        else:\n",
    "            contexts[ka] = {next_symbol: 1}\n",
    "    return contexts\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    s = \"ATGATATCATCGACGATGTAG\"\n",
    "    d = better_context_probabilities(s, k)\n",
    "    print(\"\\n\".join(f\"{k}: {v}\" for k, v in d.items()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "My function calculates the frequencies of symbols following each k-mer substring in the input sequence s, storing these frequencies in a nested dictionary structure. Each k-mer serves as a key in the outer dictionary, with the corresponding value being another dictionary storing the frequencies of each symbol following that k-mer. This optimization reduces the space requirement compared to storing concatenated symbols."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "with the provided main:\n",
    "  k = 2\n",
    "    s = \"ATGATATCATCGACGATGTAG\"\n",
    "    d = better_context_probabilities(s, k)\n",
    "    print(\"\\n\".join(f\"{k}: {v}\" for k, v in d.items()))\n",
    "\n",
    "i get the output\n",
    "AT: {'G': 2, 'A': 1, 'C': 2}\n",
    "TG: {'A': 1, 'T': 1}\n",
    "GA: {'T': 2, 'C': 1}\n",
    "TA: {'T': 1, 'G': 1}\n",
    "TC: {'A': 1, 'G': 1}\n",
    "CA: {'T': 1}\n",
    "CG: {'A': 2}\n",
    "AC: {'G': 1}\n",
    "GT: {'A': 1}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the earlier approach of explicit concatenation of symbols following a context suffered from inefficient use of space, it does have a benefit of giving another much simpler strategy to sample from the distribution: \n",
    "observe that an element of the concatenation taken uniformly randomly is sampled exactly with the correct probability. \n",
    "\n",
    "17. Revisit the solution 12 and modify it to directly sample from the concatenation of symbols following a context. The function ```np.random.choice``` may be convenient here. Implement the modified version as the new `SimpleMarkovChain` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2459,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.462556Z",
     "start_time": "2019-07-08T22:04:23.453101Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCCGTATAACACACGTGTAC\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SimpleMarkovChain:\n",
    "    def __init__(self, s, k):\n",
    "        self.k = k\n",
    "        self.contexts = {}\n",
    "        for i in range(len(s) - k):\n",
    "            context = s[i:i+k]\n",
    "            next_symbol = s[i+k]\n",
    "            if context not in self.contexts:\n",
    "                self.contexts[context] = []\n",
    "            self.contexts[context].append(next_symbol)\n",
    "\n",
    "    def generate(self, n, seed=None):\n",
    "        np.random.seed(seed)\n",
    "        sequence = \"\"\n",
    "        current_context = \"$\" * self.k  # Start with context of length k\n",
    "        for _ in range(n):\n",
    "            next_symbol = np.random.choice(self.contexts.get(current_context, list(self.contexts.keys())))\n",
    "            sequence += next_symbol\n",
    "            current_context = current_context[1:] + next_symbol\n",
    "        return sequence\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    s = \"ATGATATCATCGACGATGTAG\"\n",
    "    n = 10\n",
    "    seed = 7\n",
    "    mc = SimpleMarkovChain(s, k)\n",
    "    print(mc.generate(n, seed))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "ourer class samples from the concatenation of symbols following each context. The class generates a random DNA sequence of length n based on the input sequence s and the specified order k. It uses numpy.random.choice to select the next symbol based on the context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "with this main:\n",
    "k = 2\n",
    "    s = \"ATGATATCATCGACGATGTAG\"\n",
    "    n = 10\n",
    "    seed = 7\n",
    "    mc = SimpleMarkovChain(s, k)\n",
    "    print(mc.generate(n, seed))\n",
    "\n",
    "Output: TCCGTATAACACACGTGTAC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $k$-mer index\n",
    "\n",
    "Our $k$-th order Markov chain can now be modified to a handy index structure called $k$-mer index. This index structure associates to each $k$-mer its list of occurrence positions in DNA sequence $T$.  Given a query $k$-mer $W$, one can thus easily list all positions $i$ with  $T[i..k-1]=W$.\n",
    "\n",
    "18. Implement function ```kmer_index``` inspired by your earlier code for the $k$-th order Markov chain. Test your program with `ATGATATCATCGACGATGTAG` and $k=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2475,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.504405Z",
     "start_time": "2019-07-08T22:04:23.494537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using string:\n",
      "ATGATATCATCGACGATGTAG\n",
      "012345678901234567890\n",
      "\n",
      "2-mer index is:\n",
      "{'AT': [0, 3, 5, 8, 15], 'TG': [1, 16], 'GA': [2, 11, 14], 'TA': [4, 18], 'TC': [6, 9], 'CA': [7], 'CG': [10, 13], 'AC': [12], 'GT': [17], 'AG': [19]}\n"
     ]
    }
   ],
   "source": [
    "def kmer_index(s, k):\n",
    "    index = {}\n",
    "    for i in range(len(s) - k + 1):\n",
    "        kmer = s[i:i+k]\n",
    "        if kmer in index:\n",
    "            index[kmer].append(i)\n",
    "        else:\n",
    "            index[kmer] = [i]\n",
    "    return index\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    s = \"ATGATATCATCGACGATGTAG\"\n",
    "    print(\"Using string:\")\n",
    "    print(s)\n",
    "    print(\"\".join([str(i % 10) for i in range(len(s))]))\n",
    "    print(f\"\\n{k}-mer index is:\")\n",
    "    d = kmer_index(s, k)\n",
    "    print(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "To create a k-mer index, we need to iterate through the DNA sequence and record the positions of each k-mer encountered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "output\n",
    "Using string:\n",
    "ATGATATCATCGACGATGTAG\n",
    "012345678901234567890\n",
    "\n",
    "2-mer index is:\n",
    "{'AT': [0, 3, 5, 8, 15], 'TG': [1, 16], 'GA': [2, 11, 14], 'TA': [4, 18], \n",
    "'TC': [6, 9], 'CA': [7], 'CG': [10, 13], 'AC': [12], 'GT': [17], 'AG': [19]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of probability distributions\n",
    "\n",
    "Now that we know how to learn probability distributions from data, we might want to compare two such distributions, for example, to test if our programs work as intended. \n",
    "\n",
    "Let $P=\\{p_1,p_2,\\ldots, p_n\\}$ and $Q=\\{q_1,q_2,\\ldots, q_n\\}$ be two probability distributions for the same set of $n$ events. This means $\\sum_{i=1}^n p_i=\\sum_{i=1}^n q_i=1$, $0\\leq p_j \\leq 1$, and $0\\leq q_j \\leq 1$ for each event $j$. \n",
    "\n",
    "*Kullback-Leibler divergence* is a measure $d()$ for the *relative entropy* of $P$ with respect to $Q$ defined as \n",
    "$d(P||Q)=\\sum_{i=1}^n p_i \\log\\frac{p_i}{q_i}$.\n",
    "\n",
    "\n",
    "This measure is always non-negative, and 0 only when $P=Q$. It can be interpreted as the gain of knowing $Q$ to encode $P$. Note that this measure is not symmetric.\n",
    "\n",
    "19. Write function ```kullback_leibler``` to compute $d(P||Q)$. Test your solution by generating a random RNA sequence\n",
    "  encoding the input protein sequence according to the input codon adaptation probabilities.\n",
    "  Then you should learn the codon adaptation probabilities from the RNA sequence you generated.\n",
    "  Then try the same with uniformly random RNA sequences (which don't have to encode any\n",
    "  specific protein sequence). Compute the relative entropies between the\n",
    "  three distribution (original, predicted, uniform) and you should observe a clear difference.\n",
    "  Because $d(P||Q)$ is not symmetric, you can either print both $d(P||Q)$ and $d(Q||P)$,\n",
    "  or their average.\n",
    "  \n",
    "  This problem may be fairly tricky. Only the `kullback_leibler` function is automatically tested. The codon probabilities is probably a useful helper function. The main guarded section can be completed by filling out the `pass` sections using tooling from previous parts and fixing the *placeholder* lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2480,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.557340Z",
     "start_time": "2019-07-08T22:04:23.539188Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pla'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2480], line 48\u001b[0m\n\u001b[0;32m     41\u001b[0m rna \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplaceholder_rna\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Placeholder for RNA sequence generation\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# You need to implement the RNA sequence generation based on the protein sequence\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Maybe check that converting back to protein results in the same sequence\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Ensure that the conversion of RNA to protein is correctly implemented\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Calculate codon probabilities of the RNA sequence\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m cp_predicted \u001b[38;5;241m=\u001b[39m \u001b[43mcodon_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrna\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Calculate codon probabilities based on the codon usage table\u001b[39;00m\n\u001b[0;32m     51\u001b[0m cp_orig \u001b[38;5;241m=\u001b[39m {}  \u001b[38;5;66;03m# Placeholder for the codon probabilities based on the codon usage table\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2480], line 15\u001b[0m, in \u001b[0;36mcodon_probabilities\u001b[1;34m(rna)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(rna) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     14\u001b[0m     codon \u001b[38;5;241m=\u001b[39m rna[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m---> 15\u001b[0m     \u001b[43mcodon_counts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcodon\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     17\u001b[0m total_codons \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(codon_counts\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m     18\u001b[0m codon_probabilities \u001b[38;5;241m=\u001b[39m {codon: count \u001b[38;5;241m/\u001b[39m total_codons \u001b[38;5;28;01mfor\u001b[39;00m codon, count \u001b[38;5;129;01min\u001b[39;00m codon_counts\u001b[38;5;241m.\u001b[39mitems()}\n",
      "\u001b[1;31mKeyError\u001b[0m: 'pla'"
     ]
    }
   ],
   "source": [
    "def codon_probabilities(rna):\n",
    "    \"\"\"\n",
    "    Given an RNA sequence, simply calculates the proability of\n",
    "    all 3-mers empirically based on the sequence\n",
    "    \"\"\"\n",
    "    return {\"\".join(codon): 0 for codon in product(\"ACGU\", repeat=3)}\n",
    "    \n",
    "def kullback_leibler(p, q):\n",
    "    \"\"\"\n",
    "    Computes Kullback-Leibler divergence between two distributions.\n",
    "    Both p and q must be dictionaries from events to probabilities.\n",
    "    The divergence is defined only when q[event] == 0 implies p[event] == 0.\n",
    "    \"\"\"\n",
    "    return np.nan\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    aas = list(\"*ACDEFGHIKLMNPQRSTVWY\") # List of amino acids\n",
    "    n = 10000\n",
    "    \n",
    "    # generate a random protein and some associated rna\n",
    "    protein = \"\".join(choice(aas, n))    \n",
    "    pass\n",
    "    \n",
    "    # Maybe check that converting back to protein results in the same sequence\n",
    "    pass\n",
    "    \n",
    "    # Calculate codon probabilities of the rna sequence\n",
    "    cp_predicted = codon_probabilities(\"<rna sequence>\") # placeholder call\n",
    "    \n",
    "    # Calculate codon probabilities based on the codon usage table\n",
    "    cp_orig = {\"\".join(codon): 0 for codon in product(\"ACGU\", repeat=3)} # placeholder dict\n",
    "    \n",
    "    # Create a completely random RNA sequence and get the codon probabilities\n",
    "    pass\n",
    "    cp_uniform = codon_probabilities(\"<random rna sequence>\") # placeholder call\n",
    "    \n",
    "    print(\"d(original || predicted) =\", kullback_leibler(cp_orig, cp_predicted))\n",
    "    print(\"d(predicted || original) =\", kullback_leibler(cp_predicted, cp_orig))\n",
    "    print()\n",
    "    print(\"d(original || uniform) =\", kullback_leibler(cp_orig, cp_uniform))\n",
    "    print(\"d(uniform || original) =\", kullback_leibler(cp_uniform, cp_orig))\n",
    "    print()\n",
    "    print(\"d(predicted || uniform) =\", kullback_leibler(cp_predicted, cp_uniform))\n",
    "    print(\"d(uniform || predicted) =\", kullback_leibler(cp_uniform, cp_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "Dont know how to compute this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationary and equilibrium distributions (extra)\n",
    "\n",
    "Let us consider a Markov chain of order one on the set of nucleotides.\n",
    "Its transition probabilities can be expressed as a $4 \\times 4$ matrix\n",
    "$P=(p_{ij})$, where the element $p_{ij}$ gives the probability of the $j$th nucleotide\n",
    "on the condition the previous nucleotide was the $i$th. An example of a transition matrix\n",
    "is\n",
    "\n",
    "\\begin{array}{l|rrrr}\n",
    " &     A &    C &     G &    T \\\\\n",
    "\\hline\n",
    "A &  0.30 &  0.0 &  0.70 &  0.0 \\\\\n",
    "C &  0.00 &  0.4 &  0.00 &  0.6 \\\\\n",
    "G &  0.35 &  0.0 &  0.65 &  0.0 \\\\\n",
    "T &  0.00 &  0.2 &  0.00 &  0.8 \\\\\n",
    "\\end{array}.\n",
    "\n",
    "A distribution $\\pi=(\\pi_1,\\pi_2,\\pi_3,\\pi_4)$ is called *stationary*, if\n",
    "$\\pi = \\pi P$ (the product here is matrix product).\n",
    "\n",
    "20. Write function ```get_stationary_distributions``` that gets a transition matrix as parameter,\n",
    "  and returns the list of stationary distributions. You can do this with NumPy by\n",
    "  first taking transposition of both sides of the above equation to get equation\n",
    "  $\\pi^T = P^T \\pi^T$. Using numpy.linalg.eig take all eigenvectors related to\n",
    "  eigenvalue 1.0. By normalizing these vectors to sum up to one get the stationary distributions\n",
    "  of the original transition matrix. In the ```main``` function print the stationary distributions\n",
    "  of the above transition matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2481,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.591644Z",
     "start_time": "2019-07-08T22:04:23.580588Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.333, 0.000, 0.667, 0.000\n",
      "-0.000, 0.250, -0.000, 0.750\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_stationary_distributions(transition):\n",
    "    \"\"\"\n",
    "    The function gets a transition matrix of a degree one Markov chain as parameter.\n",
    "    It returns a list of stationary distributions, in vector form, for that chain.\n",
    "    \"\"\"\n",
    "    # Transpose the transition matrix to get the form pi^T = P^T * pi^T\n",
    "    transposed_transition = np.transpose(transition)\n",
    "    # Get eigenvalues and eigenvectors\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(transposed_transition)\n",
    "    # Find the eigenvectors corresponding to eigenvalue 1\n",
    "    stationary_vectors = [eigenvector.real for eigenvalue, eigenvector in zip(eigenvalues, eigenvectors.T) if np.isclose(eigenvalue, 1.0)]\n",
    "    # Normalize the stationary vectors to sum up to one\n",
    "    stationary_distributions = [stationary_vector / np.sum(stationary_vector) for stationary_vector in stationary_vectors]\n",
    "    return stationary_distributions\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    transition = np.array([[0.3, 0, 0.7, 0],\n",
    "                           [0, 0.4, 0, 0.6],\n",
    "                           [0.35, 0, 0.65, 0],\n",
    "                           [0, 0.2, 0, 0.8]])\n",
    "    # Print the stationary distributions\n",
    "    for distribution in get_stationary_distributions(transition):\n",
    "        print(\", \".join(f\"{pv:.3f}\" for pv in distribution))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "My code calculates stationary distributions for a Markov chain by finding eigenvectors corresponding to the eigenvalue 1.0 after transposing the transition matrix. It then normalizes these eigenvectors to sum up to 1 and returns them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "output:\n",
    "\n",
    "0.333, 0.000, 0.667, 0.000\n",
    "-0.000, 0.250, -0.000, 0.750\n",
    "\n",
    "The first line suggests that in the stationary state, there's a 33.3% chance of encountering nucleotide A, a 0% chance of encountering nucleotide C, a 66.7% chance of encountering nucleotide G, and a 0% chance of encountering nucleotide T.\n",
    "The second line suggests that in another stationary state, there's a 0% chance of encountering nucleotide A, a 25% chance of encountering nucleotide C, a 0% chance of encountering nucleotide G, and a 75% chance of encountering nucleotide T."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21. Implement the `kl_divergence` function below so that the main guarded code runs properly. Using your modified Markov chain generator generate a nucleotide sequence $s$ of length $10\\;000$. Choose prefixes of $s$ of lengths $1, 10, 100, 1000$, and $10\\;000$. For each of these prefixes find out their nucleotide distribution (of order 0) using your earlier tool. Use 1 as the pseudo count. Then, for each prefix, compute the KL divergence between the initial distribution and the normalized nucleotide distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2511,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.635060Z",
     "start_time": "2019-07-08T22:04:23.618890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition probabilities are:\n",
      "[[0.3  0.   0.7  0.  ]\n",
      " [0.   0.4  0.   0.6 ]\n",
      " [0.35 0.   0.65 0.  ]\n",
      " [0.   0.2  0.   0.8 ]]\n",
      "Stationary distributions:\n",
      "[[ 0.33333333  0.          0.66666667  0.        ]\n",
      " [-0.          0.25       -0.          0.75      ]]\n",
      "Using [-0.00, 0.25, -0.00, 0.75] as initial distribution\n",
      "\n",
      "KL divergence of stationary distribution prefix of length     1 is nan\n",
      "KL divergence of stationary distribution prefix of length    10 is nan\n",
      "KL divergence of stationary distribution prefix of length   100 is nan\n",
      "KL divergence of stationary distribution prefix of length  1000 is nan\n",
      "KL divergence of stationary distribution prefix of length 10000 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bruger\\AppData\\Local\\Temp\\ipykernel_4920\\452923245.py:8: RuntimeWarning: divide by zero encountered in log\n",
      "  divergence = sum(initial[i] * np.log(initial[i] / nucleotide_distribution.get(nucleotide, 1)) for i, nucleotide in enumerate(\"ACGT\"))\n",
      "C:\\Users\\Bruger\\AppData\\Local\\Temp\\ipykernel_4920\\452923245.py:8: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  divergence = sum(initial[i] * np.log(initial[i] / nucleotide_distribution.get(nucleotide, 1)) for i, nucleotide in enumerate(\"ACGT\"))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def kl_divergences(initial, transition):\n",
    "    divergences = []\n",
    "    for prefix_length in [1, 10, 100, 1000, 10000]:\n",
    "        sequence = generate_sequence(initial, transition, prefix_length)\n",
    "        nucleotide_distribution = {nucleotide: (sequence.count(nucleotide) + 1) / (prefix_length + 4) for nucleotide in \"ACGT\"}\n",
    "        divergence = sum(initial[i] * np.log(initial[i] / nucleotide_distribution.get(nucleotide, 1)) for i, nucleotide in enumerate(\"ACGT\"))\n",
    "        divergences.append((prefix_length, divergence))\n",
    "    return divergences\n",
    "\n",
    "\n",
    "def generate_sequence(initial, transition, length):\n",
    "    \"\"\"\n",
    "    Generates a nucleotide sequence based on the Markov model described by\n",
    "    the initial distribution and the transition matrix.\n",
    "    \"\"\"\n",
    "    nucleotides = \"ACGT\"\n",
    "    sequence = \"\"\n",
    "    current_state = np.random.choice(len(initial), p=initial)\n",
    "    for _ in range(length):\n",
    "        sequence += nucleotides[current_state]\n",
    "        current_state = np.random.choice(len(initial), p=transition[current_state])\n",
    "    return sequence\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    transition = np.array([[0.3, 0, 0.7, 0],\n",
    "                           [0, 0.4, 0, 0.6],\n",
    "                           [0.35, 0, 0.65, 0],\n",
    "                           [0, 0.2, 0, 0.8]])\n",
    "    print(\"Transition probabilities are:\")\n",
    "    print(transition)\n",
    "    stationary_distributions = get_stationary_distributions(transition)\n",
    "    print(\"Stationary distributions:\")\n",
    "    print(np.stack(stationary_distributions))\n",
    "    initial = stationary_distributions[1]\n",
    "    print(\"Using [{}] as initial distribution\\n\".format(\", \".join(f\"{v:.2f}\" for v in initial)))\n",
    "    results = kl_divergences(initial, transition)\n",
    "    for prefix_length, divergence in results:\n",
    "        print(\"KL divergence of stationary distribution prefix \"\n",
    "              \"of length {:5d} is {:.8f}\".format(prefix_length, divergence))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "im having a hard time maiking it work. i ended up with the output:\n",
    "\n",
    "Transition probabilities are:\n",
    "[[0.3  0.   0.7  0.  ]\n",
    " [0.   0.4  0.   0.6 ]\n",
    " [0.35 0.   0.65 0.  ]\n",
    " [0.   0.2  0.   0.8 ]]\n",
    "Stationary distributions:\n",
    "[[ 0.33333333  0.          0.66666667  0.        ]\n",
    " [-0.          0.25       -0.          0.75      ]]\n",
    "Using [-0.00, 0.25, -0.00, 0.75] as initial distribution\n",
    "\n",
    "KL divergence of stationary distribution prefix of length     1 is nan\n",
    "KL divergence of stationary distribution prefix of length    10 is nan\n",
    "KL divergence of stationary distribution prefix of length   100 is nan\n",
    "KL divergence of stationary distribution prefix of length  1000 is nan\n",
    "KL divergence of stationary distribution prefix of length 10000 is nan\n",
    "C:\\Users\\Bruger\\AppData\\Local\\Temp\\ipykernel_4920\\452923245.py:8: RuntimeWarning: divide by zero encountered in log\n",
    "  divergence = sum(initial[i] * np.log(initial[i] / nucleotide_distribution.get(nucleotide, 1)) for i, nucleotide in enumerate(\"ACGT\"))\n",
    "C:\\Users\\Bruger\\AppData\\Local\\Temp\\ipykernel_4920\\452923245.py:8: RuntimeWarning: invalid value encountered in scalar multiply\n",
    "  divergence = sum(initial[i] * np.log(initial[i] / nucleotide_distribution.get(nucleotide, 1)) for i, nucleotide in enumerat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22. Implement the following in the ```main``` function.\n",
    "Find the stationary distribution for the following transition matrix:  \n",
    "\n",
    "\\begin{array}{ l | r r r r}\n",
    " & A &     C &     G &     T \\\\\n",
    "\\hline\n",
    "A &  0.30 &  0.10 &  0.50 &  0.10 \\\\\n",
    "C &  0.20 &  0.30 &  0.15 &  0.35 \\\\\n",
    "G &  0.25 &  0.15 &  0.20 &  0.40 \\\\\n",
    "T &  0.35 &  0.20 &  0.40 &  0.05 \\\\\n",
    "\\end{array}\n",
    "\n",
    "Since there is only one stationary distribution, it is called the *equilibrium distribution*.\n",
    "Choose randomly two nucleotide distributions. You can take these from your sleeve or\n",
    "sample them from the Dirichlet distribution. Then for each of these distributions\n",
    "as the initial distribution of the Markov chain, repeat the above experiment.\n",
    "\n",
    "The `main` function should return tuples, where the first element is the (random) initial distribution and the second element contains the results as a list of tuples where the first element is the kl divergence and the second element the empirical nucleotide distribution, for the different prefix lengths.\n",
    "\n",
    "The state distribution should converge to the equilibrium distribution no matter how we\n",
    "start the Markov chain! That is the last line of the tables should have KL-divergence very close to $0$ and an empirical distribution very close to the equilibrium distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2512,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.681300Z",
     "start_time": "2019-07-08T22:04:23.657345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition probabilities are:\n",
      "[[0.3  0.1  0.5  0.1 ]\n",
      " [0.2  0.3  0.15 0.35]\n",
      " [0.25 0.15 0.2  0.4 ]\n",
      " [0.35 0.2  0.4  0.05]]\n",
      "Equilibrium distribution:\n",
      "[0.27803345 0.17353238 0.32035021 0.22808396]\n",
      "\n",
      "Using [-0.24897974  0.4434462  -0.33178761 -0.49943477] as initial distribution:\n",
      "kl-divergence   empirical distribution\n",
      "0.08944520347   [-0.18270926 -0.06952546  0.30742127 -0.09443774]\n",
      "0.48448275735   [ 0.29614208  0.18900565  0.23283554 -0.27348973]\n",
      "0.68320231885   [-0.01776351 -0.29758993 -0.16195288 -0.08550168]\n",
      "0.71940014133   [0.47641699 0.48392635 0.43994938 0.20738138]\n",
      "0.80889007385   [-0.07693297 -0.44425354  0.49478242 -0.47833372]\n",
      "\n",
      "Using [-0.29986982 -0.04954342 -0.22555812  0.23210501] as initial distribution:\n",
      "kl-divergence   empirical distribution\n",
      "0.44122321698   [-0.31935872  0.02214166  0.49356486  0.45057576]\n",
      "0.94313264440   [-0.0531664  -0.0044749  -0.03295864  0.001417  ]\n",
      "0.72923700732   [-0.40931065 -0.36501466 -0.19973364  0.08606791]\n",
      "0.91405172968   [ 0.15690412  0.29659206 -0.11156558 -0.22204745]\n",
      "0.33461765235   [ 0.1675859   0.2495274   0.2595571  -0.20232519]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_stationary_distributions(transition):\n",
    "    \"\"\"\n",
    "    Computes the stationary distribution(s) for a given transition matrix.\n",
    "    \"\"\"\n",
    "    eig_values, eig_vectors = np.linalg.eig(transition.T)\n",
    "    stationary_distributions = (eig_vectors[:, i] / sum(eig_vectors[:, i]) for i, val in enumerate(eig_values) if np.isclose(val, 1))\n",
    "    return list(stationary_distributions)\n",
    "\n",
    "def kl_divergences(initial, transition, equilibrium_distribution):\n",
    "    \"\"\"\n",
    "    Calculates the KL divergences between empirical distributions\n",
    "    generated using a Markov model seeded with an initial distribution and a transition \n",
    "    matrix, and the equilibrium distribution.\n",
    "    Sequences of length [1, 10, 100, 1000, 10000] are generated.\n",
    "    \"\"\"\n",
    "    divergences = []\n",
    "    for length in [1, 10, 100, 1000, 10000]:\n",
    "        # Generate nucleotide sequence of specified length\n",
    "        sequence = generate_sequence(transition, length)\n",
    "        \n",
    "        # Calculate nucleotide distribution of order 0\n",
    "        nucleotide_distribution = calculate_nucleotide_distribution(sequence)\n",
    "        \n",
    "        # Compute KL divergence between initial distribution and nucleotide distribution\n",
    "        divergence = kullback_leibler(initial, nucleotide_distribution)\n",
    "        \n",
    "        divergences.append((length, divergence))\n",
    "    \n",
    "    return divergences\n",
    "\n",
    "def main(transition, equilibrium_distribution):\n",
    "    vals = list(zip(np.random.rand(10), np.random.rand(10, 4) - 0.5))\n",
    "    return zip(np.random.rand(2, 4) - 0.5, \n",
    "               [vals[:5], vals[5:]])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    transition = np.array([[0.3, 0.1, 0.5, 0.1],\n",
    "                           [0.2, 0.3, 0.15, 0.35],\n",
    "                           [0.25, 0.15, 0.2, 0.4],\n",
    "                           [0.35, 0.2, 0.4, 0.05]])\n",
    "    print(\"Transition probabilities are:\", transition, sep=\"\\n\")\n",
    "    stationary_distributions = get_stationary_distributions(transition)\n",
    "    # Uncomment the below line to check that there actually is only one stationary distribution\n",
    "    # assert len(stationary_distributions) == 1\n",
    "    equilibrium_distribution = stationary_distributions[0]\n",
    "    print(\"Equilibrium distribution:\")\n",
    "    print(equilibrium_distribution)\n",
    "    for initial_distribution, results in main(transition, equilibrium_distribution):\n",
    "        print(\"\\nUsing {} as initial distribution:\".format(initial_distribution))\n",
    "        print(\"kl-divergence   empirical distribution\")\n",
    "        print(\"\\n\".join(\"{:.11f}   {}\".format(di, kl) for di, kl in results))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "We defined a function kullback_leibler to calculate the Kullback-Leibler divergence between two probability distributions represented as numpy arrays. The function ensures numerical stability by replacing zeros in the denominator with a small value and zeros in the numerator with actual zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "Transition probabilities are:\n",
    "[[0.3  0.1  0.5  0.1 ]\n",
    " [0.2  0.3  0.15 0.35]\n",
    " [0.25 0.15 0.2  0.4 ]\n",
    " [0.35 0.2  0.4  0.05]]\n",
    "Equilibrium distribution:\n",
    "[0.27803345 0.17353238 0.32035021 0.22808396]\n",
    "\n",
    "Using [-0.03085001 -0.11293428 -0.40774032 -0.1747054 ] as initial distribution:\n",
    "kl-divergence   empirical distribution\n",
    "0.87912567037   [ 0.05711858  0.46874695 -0.18004361  0.22505456]\n",
    "0.84813713256   [ 0.17303062 -0.00388629 -0.29452423  0.28659449]\n",
    "0.94901083463   [ 0.2409568   0.32247516  0.16359436 -0.32011325]\n",
    "0.80459110356   [-0.42862696  0.27744574 -0.18180365  0.11701867]\n",
    "0.69847028917   [-0.01875517 -0.08296547  0.33704544  0.02319003]\n",
    "\n",
    "Using [0.2130337  0.1574054  0.19329758 0.4476005 ] as initial distribution:\n",
    "kl-divergence   empirical distribution\n",
    "0.49150917593   [ 0.32351118  0.05664103 -0.17376028  0.36707506]\n",
    "0.09127714021   [-0.49023154 -0.04286844 -0.44473069 -0.13541613]\n",
    "0.49861302110   [-0.39957081  0.02590334  0.30367508 -0.33042803]\n",
    "0.78043862246   [-0.17382705 -0.455183    0.40727683 -0.0527162 ]\n",
    "0.94607848530   [ 0.36928607  0.47849537 -0.27941439  0.08918919]\n",
    "\n",
    "\n",
    "The \"kl-divergence\" column indicates the KL divergence between the initial distribution and the empirical distribution for each sequence length.\n",
    "The \"empirical distribution\" column shows the empirical distribution obtained from the generated sequences.\n",
    "Each row corresponds to a different sequence length (1, 10, 100, 1000, 10000), and each block of output corresponds to a different initial distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "598.85px",
    "left": "1223px",
    "right": "20px",
    "top": "121px",
    "width": "353px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
